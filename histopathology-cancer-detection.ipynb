{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import shutil\n",
    "import skimage.io as skio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications import inception_v3,nasnet,mobilenet,vgg19,resnet50,xception\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"../input/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2c06fe92e3ac85d5c30cec9586a5fdeed7ae8930"
   },
   "outputs": [],
   "source": [
    "file =file[file['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2'] \n",
    "file =file[file['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cbb7ad97b5c19570d2c02934e575efd4dfb60f04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220023, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1ae55d10df3a8c9a4b8b8cd930ef8f310f491bf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130907\n",
       "1     89116\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "528e03988c688d95f70fa4a49fa7a1ab0ea83c39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    80000\n",
       "0    80000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_0 = file[file['label'] == 0].sample(80000,random_state = 101)\n",
    "f_1 = file[file['label'] == 1].sample(80000,random_state = 101)\n",
    "file = pd.concat([f_0,f_1],axis=0).reset_index(drop = True)\n",
    "file = shuffle(file)\n",
    "\n",
    "file['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "616571d24773a558efc85d4b67eb46d54b57185b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128000, 2)\n",
      "(32000, 2)\n"
     ]
    }
   ],
   "source": [
    "y = file['label']\n",
    "\n",
    "x_train,x_valid = train_test_split(file,test_size = 0.20,random_state= 101,stratify=y)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4f55e4371004faad8ce5111da25bd0d707c91f0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    64000\n",
       "0    64000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "44165d9ca6d3530d49a1405af1017eb97cd1daba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16000\n",
       "0    16000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "373ff3e3900c56d3ddffa55e2b5a8a075510b2be"
   },
   "outputs": [],
   "source": [
    "def create_folder(folderName):\n",
    "    if not os.path.exists(folderName):\n",
    "        try:\n",
    "            os.makedirs(folderName)\n",
    "        except OSError as exc:\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "140fa86b4938ed2d42194a268e22178d0f5c5581"
   },
   "outputs": [],
   "source": [
    "base_dir = 'data'\n",
    "create_folder(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "926ed787da37829761d2ce080435bb36632aa661"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir,'train_dataset')\n",
    "create_folder(train_dir)\n",
    "valid_dir = os.path.join(base_dir,'valid_dataset')\n",
    "create_folder(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "64ed93a1cad6f9deca9ced239dc034096b308279"
   },
   "outputs": [],
   "source": [
    "train_tum = os.path.join(train_dir,'0')\n",
    "create_folder(train_tum)\n",
    "train_notum = os.path.join(train_dir,'1')\n",
    "create_folder(train_notum)\n",
    "\n",
    "valid_tum = os.path.join(valid_dir,'0')\n",
    "create_folder(valid_tum)\n",
    "valid_notum = os.path.join(valid_dir,'1')\n",
    "create_folder(valid_notum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "558700ea636da98fa8937ab5d10173d1a65d883f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the folders have been created\n",
    "os.listdir('data/train_dataset//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "892a526f9054ec9e9838b979ec3f4f3d70f24d7f"
   },
   "outputs": [],
   "source": [
    "# Set the id as the index in df_data\n",
    "file.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f13bbf8594833849d76de7effea1e9a07dca33ca"
   },
   "outputs": [],
   "source": [
    "# Get a list of train and val images\n",
    "train_list = list(x_train['id'])\n",
    "val_list = list(x_valid['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e66f02665dc6bd6a8350c3dd56645bceaec5391e"
   },
   "outputs": [],
   "source": [
    "# Transfer the train images\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = file.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = '0'\n",
    "    if target == 1:\n",
    "        label = '1'\n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('../input/train', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(train_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "1b01429ae7c024600cc58f90d24722d3cb7c262a"
   },
   "outputs": [],
   "source": [
    "# Transfer the val images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    # get the label for a certain image\n",
    "    target = file.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = '0'\n",
    "    if target == 1:\n",
    "        label = '1'\n",
    "    \n",
    "\n",
    "    # source path to image\n",
    "    src = os.path.join('../input/train', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(valid_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "3ab97c2c4a93c737d736a22e55667a4aca94353d"
   },
   "outputs": [],
   "source": [
    "batch_size = 90\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b607f0ee95ceecdef9918741182dda74f6232e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True)\n",
    "\n",
    "train_gen = datagen.flow_from_directory('data/train_dataset/' , \n",
    "                                        target_size = (96,96) , \n",
    "                                        batch_size = batch_size,\n",
    "                                       class_mode ='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "9ec41c8d411ef0780313546a7815011c056f61d6"
   },
   "outputs": [],
   "source": [
    "def tr_x(tr_gen):\n",
    "    for x,y in tr_gen:\n",
    "        print(x.shape)\n",
    "        yield x\n",
    "def tr_y(tr_gen):\n",
    "    for x,y in tr_gen:\n",
    "        yield y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "22b5cad20abe03237222833e1ca52d1d65534aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen = datagen.flow_from_directory('data/valid_dataset/',\n",
    "\t\t\t\t\ttarget_size = (96,96),\n",
    "\t\t\t\t\tbatch_size = batch_size,\n",
    "\t\t\t\t\tclass_mode='categorical')\n",
    "\n",
    "def va_x(val_gen):\n",
    "    for x,y in val_gen:\n",
    "        yield x\n",
    "def va_y(val_gen):\n",
    "    for x,y in val_gen:\n",
    "        yield y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "e7270f07b54139d9fba3734102c5a3f75c7abaae"
   },
   "outputs": [],
   "source": [
    "def patches(mode):\n",
    "    \n",
    "    if (mode == 'valid'):\n",
    "        xy = valid_gen\n",
    "    elif(mode == 'train'):\n",
    "        xy = train_gen\n",
    "    else:\n",
    "        xy = test_gen\n",
    "\n",
    "    batches = 0\n",
    "    for x,y in xy:\n",
    "        s = x.shape\n",
    "        print(x)\n",
    "        img = x[:,32:64,32:64,:]\n",
    "        img = np.resize(img,s)\n",
    "        batches += 1\n",
    "#         yield ([img,y],[y,img])\n",
    "        yield img,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "950115e42c4b03f7b9db2e29d2c456af7bb881e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object patches at 0x7f7620234d00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "933cf95c61713a8051774df066cbd97ca6ea8e39"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,SeparableConv2D,Dropout,Flatten,Dense,BatchNormalization,GlobalAveragePooling2D\n",
    "from keras import layers,models\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ebb47338b4694ab8210e26863e2a686d84f4245"
   },
   "source": [
    "**DENSE NET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "c4fc1edddeb971187f5e5205793b97ea67ef7f78"
   },
   "outputs": [],
   "source": [
    "def pretrained_model(model):\n",
    "    if model == 'densenet':\n",
    "        base_model = DenseNet121(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "    elif model == 'inception':\n",
    "        base_model = inception_v3.InceptionV3(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "    elif model == 'mobilenet':\n",
    "        base_model = mobilenet.MobileNet(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "    elif model == 'vgg':\n",
    "        base_model = vgg19.VGG19(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "    elif model == 'resnet':\n",
    "        base_model = resnet50.ResNet50(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "    elif model == 'xception':\n",
    "        base_model = xception.Xception(include_top=False,weights='imagenet',input_shape = (96,96,3))\n",
    "        \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(150,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(2,activation='softmax')(x)\n",
    "\n",
    "    return models.Model(base_model.input,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "f4a0fd6b3455f7f87bdddbd13e716a8c5f50d7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 6s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 96, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 96, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 48, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               691350    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 302       \n",
      "=================================================================\n",
      "Total params: 20,716,036\n",
      "Trainable params: 691,652\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "main_model = pretrained_model('vgg')\n",
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "57d56ba8a61d4855ad50680af99220e6ca67cc80"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
    "from keras.optimizers import Adam,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "56b99ab25d82122f071287d13abc101d5cffe96c"
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(\"result.csv\",separator = \",\",append=True)\n",
    "\n",
    "checkpoint_fp = \"vgg_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_fp,monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                            save_best_only= True,mode='max')\n",
    "\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                 factor = 0.1,\n",
    "                                 patience = 2,\n",
    "                                 verbose = 1,\n",
    "                                 mode = 'max',\n",
    "                                 min_lr = 0.00001)\n",
    "\n",
    "callback = [checkpoint,learning_rate,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "bdbd329a70e1ed9d6c512dc613c285c4e9253771"
   },
   "outputs": [],
   "source": [
    "steps_p_ep_tr =np.ceil(len(x_train)/batch_size)\n",
    "steps_p_ep_va =np.ceil(len(x_valid)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "6ab78114641ada7ba1fe659df844bd45d54f0d24"
   },
   "outputs": [],
   "source": [
    "main_model.compile(optimizer = Adam(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "3c48f3d9fd3c9563cdeb75316ad633f85b283f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.68 µs\n",
      "Epoch 1/10\n",
      "1423/1423 [==============================] - 572s 402ms/step - loss: 0.3979 - acc: 0.8179 - val_loss: 0.3710 - val_acc: 0.8327\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83272, saving model to vgg_model.h5\n",
      "Epoch 2/10\n",
      "1423/1423 [==============================] - 561s 394ms/step - loss: 0.3604 - acc: 0.8382 - val_loss: 0.3518 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83272 to 0.84309, saving model to vgg_model.h5\n",
      "Epoch 3/10\n",
      "1423/1423 [==============================] - 557s 391ms/step - loss: 0.3478 - acc: 0.8464 - val_loss: 0.3418 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84309 to 0.84797, saving model to vgg_model.h5\n",
      "Epoch 4/10\n",
      "1423/1423 [==============================] - 554s 389ms/step - loss: 0.3376 - acc: 0.8516 - val_loss: 0.3482 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.84797\n",
      "Epoch 5/10\n",
      " 610/1423 [===========>..................] - ETA: 4:31 - loss: 0.3315 - acc: 0.8552"
     ]
    }
   ],
   "source": [
    "%time\n",
    "my_model = main_model.fit_generator(train_gen,\n",
    "                                   steps_per_epoch = steps_p_ep_tr,\n",
    "                                   validation_data = valid_gen,\n",
    "                                   validation_steps = steps_p_ep_va,\n",
    "                                   verbose = 1,\n",
    "                                   epochs = epochs,\n",
    "                                   callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "2c880a7ff896a744e9bfe16ea50cdb7bc9da72cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  data  result.csv  vgg_model.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "f8abbc457bfbe6f0625604d964699a0022206df3"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "3be2cbd50a509e336be5c3ef3538b36d4ae494fa"
   },
   "outputs": [],
   "source": [
    "# create test_dir\n",
    "test_dir = 'test_dir'\n",
    "os.mkdir(test_dir)\n",
    "    \n",
    "# create test_images inside test_dir\n",
    "test_images = os.path.join(test_dir, 'test_images')\n",
    "os.mkdir(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "8e567a72c30103015c21dc33914c8cd2210ee1cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_images']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('test_dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "15327306b5ed4e48475647ac1d3ed7af84551780"
   },
   "outputs": [],
   "source": [
    "test_list = os.listdir('../input/test')\n",
    "\n",
    "for image in test_list:\n",
    "    \n",
    "    fname = image\n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('../input/test', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(test_images, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "aa1e8eb38b7491854dc2f826688baa1f9755a976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57458 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = datagen.flow_from_directory('test_dir/',target_size = (96,96),\n",
    "                    batch_size = batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle= False)\n",
    "\n",
    "def te(te_gen):\n",
    "    for x,y in te_gen:\n",
    "        yield ([x,y],[y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "a528937d29c91ba7be2690c73960eeb9bb6bb910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11461/57458 [====>.........................] - ETA: 2:49:08"
     ]
    }
   ],
   "source": [
    "# make sure we are using the best epoch\n",
    "main_model.load_weights('vgg_model.h5')\n",
    "\n",
    "predictions = main_model.predict_generator(test_gen, steps=57458, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "3e43f6aff8425a935987644dc5cbf574a3bf8dcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5166592, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "05ab503945b50c86185d372ea96484ec00c1bf75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5166592,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = np.argmax(predictions,axis = 1)\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "377775fdcfab4ab600bb8d8c957c14f780ba3481"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_preds = pd.DataFrame(test_preds, columns=['label'])\n",
    "\n",
    "f_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = test_gen.filenames\n",
    "\n",
    "# add the filenames to the dataframe\n",
    "f_preds['file_names'] = test_filenames\n",
    "\n",
    "f_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(x):\n",
    "    \n",
    "    # split into a list\n",
    "    a = x.split('/')\n",
    "    # split into a list\n",
    "    b = a[1].split('.')\n",
    "    extracted_id = b[0]\n",
    "    \n",
    "    return extracted_id\n",
    "\n",
    "f_preds['id'] = f_preds['file_names'].apply(extract_id)\n",
    "f_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':f_preds['id'], \n",
    "                           'label':f_preds['label'], \n",
    "                          }).set_index('id')\n",
    "\n",
    "submission.to_csv('submission_dense.csv', columns=['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
